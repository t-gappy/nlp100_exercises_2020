{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章: 係り受け解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import CaboCha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabocha = CaboCha.Parser()\n",
    "space_pattern = re.compile(r'\\u3000')\n",
    "chapter_pattern = re.compile(r'([\\n|\\r\\n|\\r]|(?<=^))([一二三四五六七八九十]+)[\\n|\\r\\n|\\r]')\n",
    "\n",
    "with open(\"../data/neko.txt\") as fr,\\\n",
    "     open(\"../data/neko.txt.cabocha\", \"w\") as fw:\n",
    "    text = fr.read()\n",
    "    text = re.sub(space_pattern, '', text)\n",
    "    text = re.sub(chapter_pattern, '', text)\n",
    "    \n",
    "    for sentence in text.split('。'):\n",
    "        sentence = sentence + '。'\n",
    "        tree = cabocha.parse(sentence)\n",
    "        print(tree.toString(CaboCha.FORMAT_LATTICE), file=fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40. 係り受け解析結果の読み込み（形態素）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morph(object):\n",
    "    def __init__(self, surface, base, pos, pos1):\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1\n",
    "        self.info = {\n",
    "            'surface': self.surface,\n",
    "            'base': self.base,\n",
    "            'pos': self.pos,\n",
    "            'pos1': self.pos1,\n",
    "        }\n",
    "    \n",
    "    def as_dict(self):\n",
    "        return self.info\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.info)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.info)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.info[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "neko_morphs = []\n",
    "with open('../data/neko.txt.cabocha') as fr:\n",
    "    sentence_morphs = []\n",
    "    for line in fr:\n",
    "        line = line.rstrip()\n",
    "        \n",
    "        if line == 'EOS':\n",
    "            neko_morphs.append(sentence_morphs)\n",
    "            sentence_morphs = []\n",
    "            continue\n",
    "        \n",
    "        if len(line) == 0\\\n",
    "        or line[0] == '*':\n",
    "            continue\n",
    "        \n",
    "        m = re.split('[\\t,]', line)\n",
    "        m = Morph(m[0], m[-3], m[1], m[2])\n",
    "        sentence_morphs.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'surface': 'どこ', 'base': 'どこ', 'pos': '名詞', 'pos1': '代名詞'},\n",
       " {'surface': 'で', 'base': 'で', 'pos': '助詞', 'pos1': '格助詞'},\n",
       " {'surface': '生れ', 'base': '生れる', 'pos': '動詞', 'pos1': '自立'},\n",
       " {'surface': 'た', 'base': 'た', 'pos': '助動詞', 'pos1': '*'},\n",
       " {'surface': 'か', 'base': 'か', 'pos': '助詞', 'pos1': '副助詞／並立助詞／終助詞'},\n",
       " {'surface': 'とんと', 'base': 'とんと', 'pos': '副詞', 'pos1': '一般'},\n",
       " {'surface': '見当', 'base': '見当', 'pos': '名詞', 'pos1': 'サ変接続'},\n",
       " {'surface': 'が', 'base': 'が', 'pos': '助詞', 'pos1': '格助詞'},\n",
       " {'surface': 'つか', 'base': 'つく', 'pos': '動詞', 'pos1': '自立'},\n",
       " {'surface': 'ぬ', 'base': 'ぬ', 'pos': '助動詞', 'pos1': '*'},\n",
       " {'surface': '。', 'base': '。', 'pos': '記号', 'pos1': '句点'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neko_morphs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 41. 係り受け解析結果の読み込み（文節・係り受け）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk(object):\n",
    "    def __init__(self, dst):\n",
    "        self.morphs = []\n",
    "        self.dst = dst\n",
    "        self.srcs = []\n",
    "        self.info = {\n",
    "            'morphs': self.morphs,\n",
    "            'dst': self.dst,\n",
    "            'srcs': self.srcs,\n",
    "        }\n",
    "        \n",
    "    def get_text(self, ignore_kv=None):\n",
    "        if ignore_kv:\n",
    "            k, v = ignore_kv\n",
    "            return ''.join([\n",
    "                m['surface'] for m in self.morphs\n",
    "                if m[k] != v\n",
    "            ])\n",
    "        else:\n",
    "            return ''.join([\n",
    "                m['surface'] for m in self.morphs\n",
    "            ])\n",
    "        \n",
    "    def search_kv(self, kv):\n",
    "        k, v = kv\n",
    "        result = [\n",
    "            m for m in self.morphs\n",
    "            if m[k] == v\n",
    "        ]\n",
    "        if len(result) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    def as_dict(self):\n",
    "        return self.info\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.info)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.info)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.morphs)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.info[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "neko_chunks = []\n",
    "with open(\"../data/neko.txt.cabocha\") as fr:\n",
    "    sentence_chunks = []\n",
    "    id_to_srcs = {}\n",
    "    \n",
    "    for line in fr:\n",
    "        line = line.rstrip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        \n",
    "        elif line == \"EOS\":\n",
    "            for chunk_id, srcs in id_to_srcs.items():\n",
    "                if chunk_id == -1:\n",
    "                    continue\n",
    "                sentence_chunks[chunk_id].srcs += srcs\n",
    "            neko_chunks.append(sentence_chunks)\n",
    "            sentence_chunks = []\n",
    "            id_to_srcs = {}\n",
    "            \n",
    "        elif line[0] == \"*\":\n",
    "            line = line.split()\n",
    "            chunk_id = int(line[1])\n",
    "            dst = int(line[2][:-1])\n",
    "            \n",
    "            sentence_chunks.append(Chunk(dst))\n",
    "            \n",
    "            if dst in id_to_srcs.keys():\n",
    "                id_to_srcs[dst].append(chunk_id)\n",
    "            else:\n",
    "                id_to_srcs[dst] = [chunk_id]\n",
    "        \n",
    "        else:\n",
    "            m = re.split('[\\t,]', line)\n",
    "            m = Morph(m[0], m[-3], m[1], m[2])\n",
    "            sentence_chunks[-1].morphs.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "しかし 9\n",
      "その 2\n",
      "当時は 5\n",
      "何という 4\n",
      "考も 5\n",
      "なかったから 9\n",
      "別段 7\n",
      "恐し 9\n",
      "いとも 9\n",
      "思わなかった。 -1\n"
     ]
    }
   ],
   "source": [
    "for c in neko_chunks[7]:\n",
    "    print(c.get_text(), c.dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 42. 係り元と係り先の文節の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dependencies = []\n",
    "for sentence_chunks in neko_chunks:\n",
    "    for c in sentence_chunks:\n",
    "        if c['dst'] == -1:\n",
    "            continue\n",
    "        src = c.get_text(ignore_kv=('pos', '記号'))\n",
    "        dst = sentence_chunks[c['dst']].get_text(ignore_kv=('pos', '記号'))\n",
    "        src_dst = src + '\\t' + dst\n",
    "        all_dependencies.append(src_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73144\n",
      "吾輩は\t猫である\n",
      "名前は\t無い\n",
      "まだ\t無い\n",
      "どこで\t生れたか\n",
      "生れたか\tつかぬ\n",
      "とんと\tつかぬ\n",
      "見当が\tつかぬ\n",
      "何でも\t薄暗い\n",
      "薄暗い\t所で\n",
      "じめじめした\t所で\n",
      "所で\t泣いて\n",
      "ニャーニャー\t泣いて\n",
      "泣いて\t記憶している\n",
      "いた事だけは\t記憶している\n",
      "吾輩は\t見た\n",
      "ここで\t始めて\n",
      "始めて\t人間という\n",
      "人間という\tものを\n",
      "ものを\t見た\n",
      "しかも\t種族であったそうだ\n"
     ]
    }
   ],
   "source": [
    "print(len(all_dependencies))\n",
    "print('\\n'.join(all_dependencies[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 43. 名詞を含む文節が動詞を含む文節に係るものを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv_dependencies = []\n",
    "for sentence_chunks in neko_chunks:\n",
    "    for c in sentence_chunks:\n",
    "        if c['dst'] == -1:\n",
    "            continue\n",
    "        \n",
    "        if c.search_kv(('pos', '名詞')):\n",
    "            dst_chunk = sentence_chunks[c['dst']]\n",
    "            \n",
    "            if dst_chunk.search_kv(('pos', '動詞')):\n",
    "                src = c.get_text(ignore_kv=('pos', '記号'))\n",
    "                dst = dst_chunk.get_text(ignore_kv=('pos', '記号'))\n",
    "                src_and_dst = src + '\\t' + dst\n",
    "                nv_dependencies.append(src_and_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29528\n",
      "どこで\t生れたか\n",
      "見当が\tつかぬ\n",
      "所で\t泣いて\n",
      "ニャーニャー\t泣いて\n",
      "いた事だけは\t記憶している\n",
      "吾輩は\t見た\n",
      "ここで\t始めて\n",
      "ものを\t見た\n",
      "あとで\t聞くと\n",
      "我々を\t捕えて\n",
      "掌に\t載せられて\n",
      "スーと\t持ち上げられた\n",
      "時\tフワフワした\n",
      "感じが\tあったばかりである\n",
      "上で\t落ちついて\n",
      "顔を\t見たのが\n",
      "ものの\t見始であろう\n",
      "ものだと\t思った\n",
      "感じが\t残っている\n",
      "今でも\t残っている\n"
     ]
    }
   ],
   "source": [
    "print(len(nv_dependencies))\n",
    "print('\\n'.join(nv_dependencies[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 44. 係り受け木の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
